import os
import csv
import pefile
import hashlib
import math
from concurrent.futures import ThreadPoolExecutor, as_completed


class PEAnalyzer:
    def __init__(self, file_path):
        self.file_path = file_path

    def extract_static_features(self):
        try:
            pe = pefile.PE(self.file_path)

            features = {}

            # 기본 파일 정보
            features['file_name'] = os.path.basename(self.file_path)
            features['file_size'] = pe.OPTIONAL_HEADER.SizeOfImage

            # 해시 값
            with open(self.file_path, 'rb') as f:
                content = f.read()
                features['md5'] = hashlib.md5(content).hexdigest()
                features['sha1'] = hashlib.sha1(content).hexdigest()
                features['sha256'] = hashlib.sha256(content).hexdigest()

            # 엔트로피
            features['entropy'] = self.calculate_entropy(content)

            # 섹션 정보
            features['num_sections'] = len(pe.sections)
            features['sections'] = []
            for section in pe.sections:
                section_info = {
                    'name': section.Name.decode().rstrip('\x00'),
                    'virtual_size': section.Misc_VirtualSize,
                    'raw_size': section.SizeOfRawData,
                    'entropy': section.get_entropy()
                }
                features['sections'].append(section_info)

            # 임포트 정보
            features['imports'] = {}
            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    features['imports'][entry.dll.decode()] = [imp.name.decode() if imp.name else '' for imp in
                                                               entry.imports]

            # 익스포트 정보
            features['exports'] = []
            if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT'):
                for exp in pe.DIRECTORY_ENTRY_EXPORT.symbols:
                    features['exports'].append(exp.name.decode() if exp.name else '')

            # 리소스 정보
            features['resources'] = []
            if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):
                for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:
                    if resource_type.name is not None:
                        name = resource_type.name
                    else:
                        name = pefile.RESOURCE_TYPE.get(resource_type.struct.Id)
                    features['resources'].append(str(name))

            # DLL 특성
            features['dll_characteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics

            return features

        except pefile.PEFormatError:
            print(f"Error: {self.file_path} is not a valid PE file.")
            return None
        except Exception as e:
            print(f"Error processing {self.file_path}: {str(e)}")
            return None

    @staticmethod
    def calculate_entropy(data):
        if not data:
            return 0
        entropy = 0
        for x in range(256):
            p_x = float(data.count(x)) / len(data)
            if p_x > 0:
                entropy += - p_x * math.log(p_x, 2)
        return entropy


def analyze_dataset(dataset_path, output_dir):
    if os.path.isfile(dataset_path):
        analyzer = PEAnalyzer(dataset_path)
        return {dataset_path: analyzer.extract_static_features()}
    elif os.path.isdir(dataset_path):
        results = {}
        with ThreadPoolExecutor() as executor:
            future_to_file = {executor.submit(PEAnalyzer(os.path.join(dataset_path, filename)).extract_static_features):
                                  filename for filename in os.listdir(dataset_path) if
                              filename.endswith('.exe') or filename.endswith('.dll')}
            for future in as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    results[file] = future.result()
                except Exception as exc:
                    print(f'{file} generated an exception: {exc}')
        return results
    else:
        raise ValueError(f"{dataset_path} is neither a file nor a directory.")


def save_features_to_csv(results, output_dir):
    # 특성별 폴더 생성
    feature_folders = ['basic_info', 'hashes', 'sections', 'imports', 'exports', 'resources']
    for folder in feature_folders:
        os.makedirs(os.path.join(output_dir, folder), exist_ok=True)

    for file, features in results.items():
        if features is None:
            continue

        md5 = features['md5']

        # 기본 정보
        with open(os.path.join(output_dir, 'basic_info', f'{md5}.csv'), 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['file_name', 'file_size', 'entropy', 'num_sections', 'dll_characteristics'])
            writer.writerow([features['file_name'], features['file_size'], features['entropy'],
                             features['num_sections'], features['dll_characteristics']])

        # 해시
        with open(os.path.join(output_dir, 'hashes', f'{md5}.csv'), 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['md5', 'sha1', 'sha256'])
            writer.writerow([features['md5'], features['sha1'], features['sha256']])

        # 섹션 정보
        with open(os.path.join(output_dir, 'sections', f'{md5}.csv'), 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['name', 'virtual_size', 'raw_size', 'entropy'])
            for section in features['sections']:
                writer.writerow([section['name'], section['virtual_size'], section['raw_size'], section['entropy']])

        # 임포트 정보
        with open(os.path.join(output_dir, 'imports', f'{md5}.csv'), 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['dll', 'imports'])
            for dll, imports in features['imports'].items():
                writer.writerow([dll, ','.join(imports)])

        # 익스포트 정보
        with open(os.path.join(output_dir, 'exports', f'{md5}.csv'), 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['exports'])
            for export in features['exports']:
                writer.writerow([export])

        # 리소스 정보
        with open(os.path.join(output_dir, 'resources', f'{md5}.csv'), 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['resources'])
            for resource in features['resources']:
                writer.writerow([resource])


# 사용 예시
if __name__ == "__main__":
    dataset_path = "path/to/your/dataset"  # 단일 파일 또는 디렉토리 경로
    output_dir = "path/to/output/directory"  # 결과를 저장할 디렉토리 경로

    results = analyze_dataset(dataset_path, output_dir)
    save_features_to_csv(results, output_dir)

    print(f"Analysis complete. Results saved in {output_dir}")